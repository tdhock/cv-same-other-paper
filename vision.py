import torch
import re
torch.__version__
import torchvision.datasets
torchvision.__version__
split_val_patterns=[
    '"(?P<split_val>.*?)"',
    "'(?P<split_val>.*?)'",
    """``(?P<split_val>[^'"]*?)``""",
]
not_again='(?! +[^ ]+ [(])'
arg_pattern = ''.join([
    ' +',
    '(?P<arg_name>[^ ]+)',
    ' [(]',
    '(?P<paren>.*?)',
    '[)]:',
    '(?P<doc>.*\n(?:%s.*\n)*)'%not_again
    ])
import os
def get_arg_dict(doc_string):
    doc_dict = {}
    for m in re.finditer(arg_pattern, doc_string):
        doc_dict[ m.groupdict()["arg_name"] ] = m.groupdict()["doc"]
    return doc_dict
[get_arg_dict(s)["split"] for s in ['`The Rendered SST2 Dataset <https://github.com/openai/CLIP/blob/main/data/rendered-sst2.md>`_.\n\n    Rendered SST2 is an image classification dataset used to evaluate the models capability on optical\n    character recognition. This dataset was generated by rendering sentences in the Standford Sentiment\n    Treebank v2 dataset.\n\n    This dataset contains two classes (positive and negative) and is divided in three splits: a  train\n    split containing 6920 images (3610 positive and 3310 negative), a validation split containing 872 images\n    (444 positive and 428 negative), and a test split containing 1821 images (909 positive and 912 negative).\n\n    Args:\n        root (string): Root directory of the dataset.\n        split (string, optional): The dataset split, supports ``"train"`` (default), `"val"` and ``"test"``.\n        transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n            version. E.g, ``transforms.RandomCrop``.\n        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n        download (bool, optional): If True, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again. Default is False.\n    ', "`WIDERFace <http://shuoyang1213.me/WIDERFACE/>`_ Dataset.\n\n    Args:\n        root (string): Root directory where images and annotations are downloaded to.\n            Expects the following folder structure if download=False:\n\n            .. code::\n\n                <root>\n                    \u2514\u2500\u2500 widerface\n                        \u251c\u2500\u2500 wider_face_split ('wider_face_split.zip' if compressed)\n                        \u251c\u2500\u2500 WIDER_train ('WIDER_train.zip' if compressed)\n                        \u251c\u2500\u2500 WIDER_val ('WIDER_val.zip' if compressed)\n                        \u2514\u2500\u2500 WIDER_test ('WIDER_test.zip' if compressed)\n        split (string): The dataset split to use. One of {``train``, ``val``, ``test``}.\n            Defaults to ``train``.\n        transform (callable, optional): A function/transform that  takes in a PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    ", '`EMNIST <https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist>`_ Dataset.\n\n    Args:\n        root (string): Root directory of dataset where ``EMNIST/raw/train-images-idx3-ubyte``\n            and  ``EMNIST/raw/t10k-images-idx3-ubyte`` exist.\n        split (string): The dataset has 6 different splits: ``byclass``, ``bymerge``,\n            ``balanced``, ``letters``, ``digits`` and ``mnist``. This argument specifies\n            which one to use.\n        train (bool, optional): If True, creates dataset from ``training.pt``,\n            otherwise from ``test.pt``.\n        download (bool, optional): If True, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n        transform (callable, optional): A function/transform that  takes in an PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n    ']]
for data_name in dir(torchvision.datasets):
    data_class = getattr(torchvision.datasets, data_name)
    ann_dict = getattr(data_class.__init__, "__annotations__", {})
    doc_string = data_class.__doc__
    if type(doc_string) is type(""):
        out_txt=os.path.expanduser("~/teaching/regex-tutorial/torchvision-docs/"+data_name+".txt")
        f=open(out_txt, "w", encoding="utf-8")
        f.write(doc_string)
        f.close()
        doc_dict = get_arg_dict(doc_string)
        ##print({data_name:doc_dict.keys()})
        if "split" in doc_dict and "train" in doc_dict:
            print(data_name)
        if "split" in doc_dict:
            split_doc = doc_dict["split"]
            split_val_list = []
            for pattern in split_val_patterns:
                for m in re.finditer(pattern, split_doc):
                    split_val_list.append(m.groupdict()["split_val"])
            print({data_name:(split_val_list, split_doc)})
